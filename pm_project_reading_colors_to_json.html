<!DOCTYPE html>
<html>
<head>
<link rel="Stylesheet" type="text/css" href="style.css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<title>pm_project_reading_colors_to_json</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<p>
<a href="index.html">Index</a>
</p>

<p>
<a href="pmount_index.html">PMount</a>
</p>

<div id="Reading Colors to JSON"><h1 id="Reading Colors to JSON" class="header"><a href="#Reading Colors to JSON">Reading Colors to JSON</a></h1></div>


<table>
<tr>
<td>
I want to get a list of common colors in a sequence of images. I'm bringing in sequences of images with around 30 colors per sequence (they are comic book style). I want to make a json list of RGB colors. I can do this in Nuke using the 'sample' method in Python, but it's slow. Can I use some other tool (inside or outside Nuke) to achieve this more efficiently and faster. For example I've heard the 'Open Image IO' may be faster. I'm open to any ideas.
</td>
</tr>
</table>

<p>
The slow performance of Nuke's Python sample method is a common issue because it incurs overhead from the Nuke evaluation engine. To achieve this more efficiently and faster, you should move the image processing outside of the Nuke Python API and use high-performance, dedicated Python libraries.
</p>

<p>
The best approach for finding a limited set of dominant colors is to use a Machine Learning/Statistical Clustering method, specifically K-Means Clustering, which is highly optimized in popular scientific libraries.
</p>

<p>
Here is the most efficient solution, combining fast I/O and statistical processing:
</p>

<div id="Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn"><h2 id="Recommended Solution: External Python with NumPy + Scikit-learn" class="header"><a href="#Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn">Recommended Solution: External Python with NumPy + Scikit-learn</a></h2></div>

<p>
This method is significantly faster because it uses optimized C/C++ backend libraries (like NumPy) for file reading and computation, bypassing Nuke's slower internal Python wrappers.
</p>

<div id="Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn-The Strategy: K-Means Clustering"><h3 id="The Strategy: K-Means Clustering" class="header"><a href="#Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn-The Strategy: K-Means Clustering">The Strategy: K-Means Clustering</a></h3></div>

<p>
Since your images are "comic book style" with a naturally limited number of distinct colors (around 30), K-Means Clustering is the ideal algorithm.
</p>
<ul>
<li>
<span id="Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn-The Strategy: K-Means Clustering-How it works"></span><strong id="How it works">How it works</strong>: It groups all the pixels in an image into K clusters (where K is the number of colors you expect, e.g., K=30). The center of each cluster (centroid) is one of your dominant colors.

<li>
<span id="Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn-The Strategy: K-Means Clustering-Speed"></span><strong id="Speed">Speed</strong>: Libraries like Scikit-learn or OpenCV implement K-Means using highly optimized algorithms that can process millions of pixels quickly.

</ul>
<div id="Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn-The Tools"><h3 id="The Tools" class="header"><a href="#Reading Colors to JSON-Recommended Solution: External Python with NumPy + Scikit-learn-The Tools">The Tools</a></h3></div>

<table>
<tr>
<td>
Tool
</td>
<td>
Purpose	Why it's Fast
</td>
<td>
&nbsp;
</td>
</tr>
<tr>
<td>
NumPy
</td>
<td>
High-performance, low-level array manipulation.
</td>
<td>
Core of Python scientific computing, operates on pre-compiled C/C++ code.
</td>
</tr>
<tr>
<td>
OpenCV (cv2) or PIL/Pillow
</td>
<td>
Fast image loading and pixel access.
</td>
<td>
Optimized for reading and writing large image data efficiently.
</td>
</tr>
<tr>
<td>
Scikit-learn (sklearn)
</td>
<td>
Implements the fast K-Means Clustering algorithm.
</td>
<td>
Excellent, robust, and fast statistical library.
</td>
</tr>
<tr>
<td>
OpenImageIO (OIIO)
</td>
<td>
Optional. The Python bindings are great for VFX file formats (EXR, TIFF, etc.), offering fast, consistent I/O, as you suspected.
</td>
<td>
Specifically designed for high-performance reading of image sequences in a production pipeline.
</td>
</tr>
</table>

<div id="Reading Colors to JSON-Python Code Example (K-Means)"><h2 id="Python Code Example (K-Means)" class="header"><a href="#Reading Colors to JSON-Python Code Example (K-Means)">Python Code Example (K-Means)</a></h2></div>

<p>
This script iterates through your sequence, processes each frame for K=30 colors, and aggregates the results.
</p>

<pre python>
import numpy as np
import cv2  # You could use Pillow or OIIO instead of OpenCV
from sklearn.cluster import MiniBatchKMeans
import json
import glob
import os

def extract_dominant_colors_sequence(sequence_path, num_colors=30, frames=None):
    """
    Extracts the dominant RGB colors from a sequence of images using MiniBatchKMeans.
    
    Args:
        sequence_path (str): File path pattern (e.g., '/path/to/img.%04d.exr').
        num_colors (int): The target number of dominant colors (K).
        frames (list): Optional list of frame numbers to process (e.g., [1, 10, 20]).
    
    Returns:
        dict: A dictionary mapping frame numbers to a list of RGB color lists.
    """
    
    all_dominant_colors = {}
    
    if not frames:
        # Simple glob to find all files if frame list isn't provided
        # NOTE: This part needs careful handling for frame number parsing if not using Nuke's native Read node features
        print("Warning: Processing a basic file glob. Consider using OIIO for robust sequence handling.")
        file_list = sorted(glob.glob(sequence_path.replace('%04d', '*')))
        
        # Simple frame number extraction for file_list:
        frame_list = [os.path.basename(f).split('.')[1] for f in file_list]
        file_frame_pairs = zip(file_list, frame_list)
        
    else:
        # Use nuke.frame() functionality replacement for a range of frames
        def get_frame_path(frame_num):
            # Assumes the sequence path uses Nuke-style padding (e.g., %04d)
            return sequence_path % frame_num
        
        file_frame_pairs = [(get_frame_path(f), str(f)) for f in frames]


    for file_path, frame_num_str in file_frame_pairs:
        try:
            # 1. Load Image (using OpenCV for speed)
            # flag=1 loads as BGR (color), flag=-1 loads all channels including alpha
            img = cv2.imread(file_path)
            if img is None:
                print(f"Skipping frame {frame_num_str}: Could not load image.")
                continue

            # Convert BGR (OpenCV default) to RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # 2. Reshape and Normalize Pixel Data
            # Reshape the image array to a list of pixels (N rows, 3 columns for R, G, B)
            pixels = img.reshape((-1, 3))
            pixels = np.float32(pixels)

            # 3. Apply K-Means Clustering (using MiniBatchKMeans for even more speed)
            # This finds 'num_colors' representative colors
            kmeans = MiniBatchKMeans(n_clusters=num_colors, n_init='auto', random_state=42)
            kmeans.fit(pixels)
            
            # The cluster centers are the dominant colors
            dominant_colors = kmeans.cluster_centers_

            # 4. Format Output: Convert float RGB (0-255) to integer list
            # The result is a list of [R, G, B] lists
            color_list = dominant_colors.astype(int).tolist()
            
            all_dominant_colors[frame_num_str] = color_list
            print(f"Processed frame {frame_num_str}: Found {len(color_list)} colors.")

        except Exception as e:
            print(f"Error processing frame {frame_num_str}: {e}")
            
    # 5. Output to JSON
    json_output = json.dumps(all_dominant_colors, indent=4)
    return json_output

# --- Example Usage ---
# NOTE: Replace 'read_node_file_path' with the actual file sequence path.
# Example path with Nuke-style padding:
# read_node_file_path = '/path/to/my/comic/scene_1.shot_01.%04d.exr'
# frames_to_process = list(range(101, 201))  # Process frames 101 through 200

# # Run the function
# json_data = extract_dominant_colors_sequence(read_node_file_path, num_colors=30, frames=frames_to_process)

# # Save the JSON file
# with open('comic_palette.json', 'w') as f:
#     f.write(json_data)

</pre>

<div id="Reading Colors to JSON-The OpenImageIO (OIIO) Option"><h2 id="The OpenImageIO (OIIO) Option" class="header"><a href="#Reading Colors to JSON-The OpenImageIO (OIIO) Option">The OpenImageIO (OIIO) Option</a></h2></div>

<p>
You specifically mentioned OpenImageIO. This is an excellent idea, especially if your pipeline uses complex file formats like OpenEXR, TIFF, or DPX.
</p>

<ul>
<li>
<span id="Reading Colors to JSON-The OpenImageIO (OIIO) Option-Integration"></span><strong id="Integration">Integration</strong>: Use the Python bindings for OIIO (import OpenImageIO as OIIO).

<li>
<span id="Reading Colors to JSON-The OpenImageIO (OIIO) Option-Fast Reading"></span><strong id="Fast Reading">Fast Reading</strong>: Replace cv2.imread(file_path) with OIIO code to read the image data into a NumPy array (which OIIO handles natively).

<li>
<span id="Reading Colors to JSON-The OpenImageIO (OIIO) Option-Process"></span><strong id="Process">Process</strong>: Pass the NumPy array directly to the K-Means clustering step (as shown above).

</ul>
<p>
This separates the fast I/O (OIIO) from the fast computation (NumPy/Scikit-learn), maximizing efficiency.
</p>

<div id="Reading Colors to JSON-The OpenImageIO (OIIO) Option-OIIO Replacement for cv2.imread:"><h3 id="OIIO Replacement for cv2.imread:" class="header"><a href="#Reading Colors to JSON-The OpenImageIO (OIIO) Option-OIIO Replacement for cv2.imread:">OIIO Replacement for cv2.imread:</a></h3></div>

<pre python>
import OpenImageIO as OIIO
import numpy as np
# ... (rest of your imports)

def read_image_with_oiio(file_path):
    """Loads an image into a NumPy array using OpenImageIO."""
    
    # 1. Read the image and spec
    img_input = OIIO.ImageInput.open(file_path)
    if not img_input:
        raise IOError(f"Could not open image with OIIO: {OIIO.geterror()}")

    spec = img_input.spec()
    
    # 2. Create NumPy array and read pixel data
    # Read as float type and get R, G, B channels
    pixel_data = np.empty((spec.height, spec.width, spec.nchannels), dtype=np.float32)
    img_input.read_image(0, 0, spec.nchannels, OIIO.TypeDesc.FLOAT, pixel_data)
    img_input.close()
    
    # Only return the first 3 channels (R, G, B), dropping Alpha if present
    return (pixel_data[:, :, :3] * 255.0).astype(np.uint8) # Convert to 0-255 range for clustering
</pre>

<p>
You would then call this function within your main loop and feed the resulting array to the clustering steps.
</p>

<p>
<a href="pmount_index.html">PMount</a>
</p>

<p>
<a href="index.html">Index</a>
</p>

</body>
</html>
